{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fcda9ded7e4ec08f5f7ebff304bea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f532f676e2d547beaccbf9b954ec025f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75566b8caa2496b8202ec25ad39820c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "base_model_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    #quantization_config=bnb_config,\n",
    "    #device_map=\"auto\",\n",
    "    use_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89659a5b7bc4a99894ede73294f4d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9942d65af44bdab0795767cb61d198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5737ffa1f21e4df7b45fe97b9c15dc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b2a67b10284eca83ac26d6dddd9187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 0 ns, total: 1.9 s\n",
      "Wall time: 124 ms\n",
      "tensor([[[ -4.6822,   0.9866,   4.5126,  ...,  -5.2010,  -2.1646,  -4.2286],\n",
      "         [-10.1421, -10.1378,   5.6231,  ...,  -6.1040, -11.0720,  -4.8641],\n",
      "         [ -9.6640,  -9.2623,   4.9745,  ...,  -7.9037, -11.2208,  -3.2938],\n",
      "         [ -8.7681,  -8.3673,   8.2792,  ...,  -5.3513,  -8.6309,  -3.2394]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "text = \"Sample input.\"\n",
    "\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "%time output = model(input_ids)\n",
    "print(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.zamba2 import Zamba2Config, Zamba2Model\n",
    "config = Zamba2Config(# hidden_size=256,\n",
    "                    use_cache=False,\n",
    "                    use_mamba_kernels=True)\n",
    "\n",
    "model = Zamba2Model(config)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zamba requires an initialized `HybridMambaAttentionDynamicCache` to return a cache. None was provided, so no cache will be returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[ 0.2320, -0.0671,  0.4281,  ...,  0.2731, -0.2485, -0.1961],\n",
      "         [-0.3529, -0.3817,  0.1831,  ...,  0.4370,  0.1053,  0.2115]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720e33f02b90>\n",
      "tensor([[[-0.2456, -0.1861, -0.3472,  ...,  0.2924, -0.3361,  0.0805],\n",
      "         [-0.2854, -0.3549,  0.2099,  ...,  0.2326, -0.2619,  0.0898]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[ 0.3210,  0.0659,  0.5195,  ...,  0.2646, -0.4936, -0.3867],\n",
      "         [-0.0319,  0.0588,  0.0368,  ...,  0.2150, -0.6552, -0.3597]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720e33f02b90>\n",
      "tensor([[[-0.2532, -0.1881, -0.3141,  ...,  0.6968, -0.3180, -0.1367],\n",
      "         [-0.5472, -0.2829,  0.1529,  ...,  0.4406, -0.1009, -0.1136]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[ 0.2028,  0.5285,  0.4683,  ...,  0.4778, -0.1321, -0.1004],\n",
      "         [-0.1195,  0.1437, -0.2211,  ...,  0.3486, -0.2087,  0.0910]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720e33f02b90>\n",
      "tensor([[[-0.0541, -0.1016, -0.1723,  ...,  0.2633,  0.2065, -0.2020],\n",
      "         [-0.2931, -0.6119,  0.3172,  ...,  0.2568,  0.1691, -0.4037]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[ 0.0046,  0.8110,  0.4117,  ...,  0.4044, -0.2058,  0.0540],\n",
      "         [-0.1387,  0.6083, -0.0321,  ...,  0.3768, -0.2296, -0.0283]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720e33f02b90>\n",
      "tensor([[[-0.4597,  0.0150,  0.1303,  ...,  0.2195, -0.0543, -0.1967],\n",
      "         [-0.6164, -0.3430,  0.2792,  ...,  0.0399,  0.0801, -0.6702]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[ 0.0241,  0.6656,  0.1877,  ...,  0.0557, -0.2189,  0.1564],\n",
      "         [-0.3077,  0.5369, -0.1785,  ...,  0.1834, -0.2878,  0.1950]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720e33f02b90>\n",
      "tensor([[[-0.2831,  0.1347,  0.1499,  ...,  0.0057,  0.1145, -0.0469],\n",
      "         [-0.3922, -0.2633,  0.0517,  ..., -0.1507, -0.0124, -0.4252]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[-0.0641,  0.8043,  0.4550,  ...,  0.2877, -0.0341,  0.3485],\n",
      "         [-0.2425,  0.7751,  0.0793,  ...,  0.4592,  0.1067,  0.2118]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720e33f02b90>\n",
      "tensor([[[-0.0197,  0.0272,  0.3330,  ...,  0.0538, -0.0269, -0.1854],\n",
      "         [-0.3365, -0.2644,  0.1057,  ..., -0.1096,  0.0154, -0.5892]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<function MLP.__init__.<locals>.glu at 0x720f6c155120>\n",
      "tensor([[[-0.4278,  0.5207,  0.1612,  ...,  0.1028,  0.2516,  0.2261],\n",
      "         [-0.5387,  0.3975,  0.0550,  ...,  0.2629,  0.2234,  0.3841]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPast(last_hidden_state=tensor([[[ 1.5610, -0.2107, -0.1899, -0.6792,  0.1004, -1.4207,  0.4914,\n",
       "          -2.6973, -1.5301,  0.8072,  0.1398,  0.3223,  0.7193, -0.6386,\n",
       "          -0.0224, -0.0305,  1.0239,  1.1427,  0.5567, -1.2266,  1.0427,\n",
       "          -0.2688,  0.3386, -0.3193, -0.7158,  0.4627, -0.0887, -0.3950,\n",
       "           0.4347,  0.6391, -0.1739, -1.6352,  1.1399,  0.4062,  0.2984,\n",
       "          -1.9093,  0.3013,  2.0630, -0.8852, -0.8784,  0.8980, -0.7977,\n",
       "           0.8236, -0.5900, -0.1444,  1.0169, -0.0153,  2.7408, -1.3365,\n",
       "          -0.1727, -0.4123, -2.5188,  0.4768, -1.0458,  0.2904, -0.3563,\n",
       "           1.6769, -0.3954, -0.3084, -0.5172, -1.7214,  1.7523,  0.7369,\n",
       "           1.1858,  0.1346,  0.0534,  0.9420,  1.2791, -0.2385,  0.3122,\n",
       "           0.8081, -1.1902,  1.1936,  0.7331, -1.4534,  0.5935,  0.7391,\n",
       "          -0.9888, -0.2075,  0.6612,  0.8746, -0.3961, -0.5769, -1.5450,\n",
       "           1.4662, -0.3326,  1.2070, -0.0269, -0.3110,  1.7675,  0.9386,\n",
       "           0.0231, -0.5033,  0.4606,  0.0376, -0.6718, -2.2408, -0.4152,\n",
       "          -0.0150,  1.6197, -0.2152, -0.9927, -0.0088, -0.1774, -0.8367,\n",
       "          -0.2404,  1.7812,  0.6681, -1.5299, -1.3167,  1.1307,  2.4472,\n",
       "           0.9099, -0.4268, -0.6490,  0.0145,  1.7519,  0.6995,  0.2697,\n",
       "           0.2662,  0.0143, -1.0016, -0.6653, -0.6398, -0.4175, -0.8453,\n",
       "           1.8385, -0.2844, -1.6901,  0.6662, -0.4793, -0.1196,  1.4028,\n",
       "           1.1849, -1.4733,  0.5708,  0.1397,  0.7665,  1.4205, -1.6913,\n",
       "           0.2976,  1.3293,  0.4003,  1.6835,  0.1577,  0.0323,  0.2776,\n",
       "          -0.9257,  0.5199,  0.3320,  0.2912, -1.1751, -0.0050, -0.2424,\n",
       "          -1.1217, -0.6652, -0.0812, -1.1894, -0.1066,  0.4753, -0.6588,\n",
       "           1.1274, -2.2381,  0.1637, -0.8203,  0.4781,  0.0622, -0.7859,\n",
       "          -1.7128,  1.2858, -0.1512, -1.1712, -0.5319,  0.5512, -1.4268,\n",
       "           0.2548,  2.9298,  0.7842, -0.1890, -0.8952,  0.1479, -0.0825,\n",
       "          -0.2476, -0.0274,  1.9373,  1.2561, -0.3870, -0.5059,  1.0771,\n",
       "           0.7161,  0.2510, -0.7403,  0.8498, -0.2442,  1.5790,  0.2348,\n",
       "           0.0841,  2.0146,  0.8968,  0.2489, -0.9310,  1.7749, -1.3079,\n",
       "           0.7295,  0.8599,  0.0189,  1.6884, -0.5464,  1.6790, -0.7889,\n",
       "           0.2329,  0.8090, -1.8518, -0.1529, -0.9284, -0.2809,  0.7448,\n",
       "          -0.4769, -2.0393, -1.5564,  0.1528,  1.8674, -0.0044,  1.1340,\n",
       "           0.9800, -0.9253, -0.4846,  1.1367,  1.0322,  1.7122,  1.1982,\n",
       "          -0.0808,  1.1228, -0.9897, -0.7876, -0.2427,  1.1697,  0.0605,\n",
       "           0.8717, -0.1591, -0.1623, -0.9304, -1.2984,  1.0778,  0.2340,\n",
       "           0.4645,  0.5720, -0.0596,  1.1844,  1.2052, -0.6137,  1.2002,\n",
       "           0.0232, -1.2396, -0.4822,  1.4322],\n",
       "         [ 0.6106, -1.1350,  1.0885, -0.6590,  1.1972,  1.4557,  0.4810,\n",
       "           1.6009, -0.8303,  1.0261,  0.8802, -1.5162, -0.0897,  1.2317,\n",
       "          -0.1939, -0.1571, -0.1656, -0.7842,  0.8784, -0.0210,  0.4554,\n",
       "          -1.6171,  2.7235,  1.7553,  0.9623, -1.7567,  1.3346, -1.1969,\n",
       "          -0.0813, -0.7047,  0.2750, -1.3842, -0.2213,  0.2764,  0.1043,\n",
       "          -0.5828, -1.7812,  1.3242,  0.5183,  0.6814,  0.2051,  1.0487,\n",
       "          -1.4249, -0.5231,  0.8032, -0.7084, -0.3434,  0.2496,  1.2076,\n",
       "          -1.8979,  1.0625,  1.8654, -1.5041,  1.3455,  0.9795,  0.0224,\n",
       "           1.3700, -1.2286, -0.1811,  0.3205, -0.8475,  0.5566,  3.2508,\n",
       "           0.0792, -1.6544, -0.1888,  0.4788, -0.4847,  1.1109, -0.4203,\n",
       "           1.2064,  1.8857,  1.7834, -1.5793, -1.9296,  1.1148,  0.9699,\n",
       "           0.5867,  0.4809, -0.7841, -1.2050,  1.0947,  0.4143, -1.0028,\n",
       "          -0.4719, -1.3144, -0.3814,  0.7144,  0.9841, -0.6150,  1.0012,\n",
       "          -0.3843,  1.4516, -0.1925,  0.5752, -0.3950,  1.8073,  0.4228,\n",
       "           0.1050, -0.2622, -0.6314, -0.9772, -1.6765,  1.1153, -0.1649,\n",
       "           0.2459,  0.7048, -0.7455, -0.9480,  1.5142,  0.9590, -2.4351,\n",
       "           0.6375, -0.8491, -0.3248, -1.4186,  0.4533,  2.3914,  0.2982,\n",
       "          -0.6675, -1.3668,  0.6553,  1.5135, -0.9250, -0.0102,  1.2277,\n",
       "          -0.7793, -0.7797,  0.3316, -0.6598,  0.0769, -0.8516, -0.1348,\n",
       "          -0.2179, -0.1757,  0.6741, -0.8688,  2.0086, -1.6593, -0.2141,\n",
       "           0.3545,  0.7880, -1.1431,  0.8881, -1.2641, -0.1263, -0.3227,\n",
       "          -0.2829, -0.4671, -0.2100,  1.2006, -0.3661,  0.2646,  0.5560,\n",
       "           0.5605, -0.6277,  0.2558, -0.4180, -0.6891,  0.5311,  0.7269,\n",
       "          -0.0822, -0.1792, -0.7969, -0.3833,  0.8326, -1.1468, -0.4691,\n",
       "          -2.6068,  0.0915,  1.0277,  0.1904, -0.4176, -0.8701,  1.1830,\n",
       "          -1.3595, -0.2752,  0.1232,  1.0058,  1.6270,  0.6452,  0.3897,\n",
       "          -0.8015, -0.2148,  1.2683, -0.4499, -0.1746,  0.8048,  0.7027,\n",
       "           1.0295,  0.5364, -0.6913, -1.3428, -0.3413, -0.1128, -0.4508,\n",
       "          -0.2579, -0.3001, -1.0598,  0.1322,  1.2603, -0.5473, -0.0878,\n",
       "           1.2313, -0.9989, -0.2355, -0.9956,  1.5185,  1.7814, -0.2523,\n",
       "          -0.7115, -0.2909, -0.5441, -0.3842, -1.5203,  0.4054,  0.3819,\n",
       "           0.4151,  0.7575,  0.0335,  0.2037, -1.5995, -0.7745,  1.0326,\n",
       "          -1.2516, -0.6565,  0.0148, -0.7770, -1.0470,  0.6955, -1.2700,\n",
       "           1.1997,  1.7305, -1.0536,  0.3510, -0.8766, -0.6916,  0.4194,\n",
       "           0.9248, -1.7707, -0.9460, -0.9431,  0.5791,  0.6802, -0.2858,\n",
       "          -0.2782,  0.9059, -1.2144, -0.3521, -1.0666,  0.5210,  2.3597,\n",
       "          -0.6880,  1.1041, -1.7320,  1.5964]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>), past_key_values=None, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inp = torch.tensor([[1, 2]]).cuda()\n",
    "model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
